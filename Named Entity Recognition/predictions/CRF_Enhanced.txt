C:\Users\Harshith Guru Prasad\Desktop\NLP_HW6>python main.py -T crf -e data/twitter_dev.ner data/twitte
r_dev_test.ner
.. # train sents 1804
.. # data/twitter_dev.ner sents 590
.. # data/twitter_dev_test.ner sents 703
Twitter data loaded.
Classes: 21 ['B-company' 'B-facility' 'B-geo-loc' 'B-movie' 'B-musicartist' 'B-other'
 'B-person' 'B-product' 'B-sportsteam' 'B-tvshow' 'I-company' 'I-facility'
 'I-geo-loc' 'I-movie' 'I-musicartist' 'I-other' 'I-person' 'I-product'
 'I-sportsteam' 'I-tvshow' 'O']
-- 0 features added.
-- 1000 features added.
-- 2000 features added.
-- 3000 features added.
-- 4000 features added.
-- 5000 features added.
-- 6000 features added.
-- 7000 features added.
-- 8000 features added.
-- 9000 features added.
-- 10000 features added.
-- 11000 features added.
-- 12000 features added.
-- 13000 features added.
-- 14000 features added.
-- 15000 features added.
-- 16000 features added.
-- 17000 features added.
-- 18000 features added.
-- 19000 features added.
-- 20000 features added.
-- 21000 features added.
-- 22000 features added.
-- 23000 features added.
-- 24000 features added.
-- 25000 features added.
-- 26000 features added.
-- 27000 features added.
-- 28000 features added.
-- 29000 features added.
-- 30000 features added.
-- 31000 features added.
-- 32000 features added.
-- 33000 features added.
-- 34000 features added.
-- 35000 features added.
-- 36000 features added.
-- 37000 features added.
-- 38000 features added.
-- 39000 features added.
-- 40000 features added.
-- 41000 features added.
-- 42000 features added.
-- 43000 features added.
-- 44000 features added.
-- 45000 features added.
1804 45421
Number of weights 954324
Starting training
iteration 0
avg loss: 0.080270 w: [[ 2. -1. -2. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 1
avg loss: 0.062922 w: [[ 4. -1. -2. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 2
avg loss: 0.048723 w: [[ 5.  1. -3. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 3
avg loss: 0.039763 w: [[ 6.  1. -2. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 4
avg loss: 0.031776 w: [[ 4.  1.  1. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 5
avg loss: 0.022844 w: [[ 5.  2.  3. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 6
avg loss: 0.023274 w: [[ 5.  1.  1. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 7
avg loss: 0.013913 w: [[ 4.  1.  1. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 8
avg loss: 0.011279 w: [[ 6.  1.  3. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 9
avg loss: 0.007672 w: [[ 6.  0.  3. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 10
avg loss: 0.008903 w: [[ 5.  1.  1. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 11
avg loss: 0.006985 w: [[ 5.  1.  2. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 12
avg loss: 0.006785 w: [[ 5.  1.  3. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 13
avg loss: 0.003865 w: [[ 5.  1.  3. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 14
avg loss: 0.003865 w: [[ 5.  1.  2. ...,  0.  0.  0.]]
effective learning rate: 1.000000
iteration 15
avg loss: 0.004065 w: [[ 5.  2.  2. ...,  0.  0.  0.]]

effective learning rate: 1.000000
iteration 16
avg loss: 0.004094 w: [[ 5.  2.  2. ...,  0.  0.  0.]
]teration 17

effective learning rate: 1.000000
iteration 17
avg loss: 0.004924 w: [[ 5.  1.  3. ...,  0.  0.  0.]
]ffective learning rate: 1.000000

effective learning rate: 1.000000
iteration 18
avg loss: 0.004924 w: [[ 5.  1.  3. ...,  0.  0. 
 0.]
]
effective learning rate: 1.000000
iteration 18
avg loss: 0.004924 w: [[ 5.  1.  3. ...,  0.  0
.
 0.]]
effective learning rate: 1.000000
iteration 18
avg loss: 0.004924 w: [[ 5.  1.  3. ...,  0.  
0
.  0.]]
effective learning rate: 1.000000
iteration 18
avg loss: 0.004924 w: [[ 5.  1.  3. ...,  0.
 0.  0.]]
effective learning rate: 1.000000
iteration 18
avg loss: 0.005382 w: [[ 5.  1.  2. ...,  0.
 0.  0.]]
effective learning rate: 1.000000
iteration 19
avg loss: 0.003807 w: [[ 4.  1.  2. ...,  0.
 0.  0.]]
effective learning rate: 1.000000
iteration 20
avg loss: 0.002376 w: [[ 5.  2.  3. ...,  0.
 0.  0.]]
effective learning rate: 1.000000
iteration 21
avg loss: 0.002720 w: [[ 5.  2.  2. ...,  0.
 0.  0.]]
effective learning rate: 1.000000
iteration 22
avg loss: 0.001689 w: [[ 5.  3.  2. ...,  0.
 0.  0.]]
effective learning rate: 1.000000
iteration 23
avg loss: 0.001288 w: [[ 5.  3.  2. ...,  0.
 0.  0.]]
effective learning rate: 1.000000
iteration 24
avg loss: 0.001202 w: [[ 5.  3.  2. ...,  0.
 0.  0.]]
effective learning rate: 1.000000
### Train evaluation; writing to ./twitter_tr
ain.ner.pred
Token-wise accuracy 99.7566701019
Token-wise F1 (macro) 98.2818545158
Token-wise F1 (micro) 99.7566701019
Sentence-wise accuracy 97.0066518847
               precision    recall  f1-score
  support

    B-company       0.99      0.96      0.97
      135
   B-facility       0.99      0.99      0.99
       76
    B-geo-loc       1.00      0.95      0.97
      199
      B-movie       1.00      1.00      1.00
       27
B-musicartist       1.00      1.00      1.00
       42
      B-other       0.99      0.90      0.94
      162
     B-person       1.00      0.98      0.99
      341
    B-product       1.00      0.92      0.96
       78
 B-sportsteam       1.00      1.00      1.00
       40
     B-tvshow       1.00      1.00      1.00
       23
    I-company       0.97      1.00      0.98
       29
   I-facility       1.00      0.99      0.99
       76
    I-geo-loc       1.00      0.91      0.96
       35
      I-movie       1.00      1.00      1.00
       35
I-musicartist       1.00      1.00      1.00
       46
      I-other       0.99      0.90      0.95
      239
     I-person       1.00      1.00      1.00
      154
    I-product       1.00      0.94      0.97
       64
 I-sportsteam       1.00      0.95      0.97
       19
     I-tvshow       1.00      1.00      1.00
       21
            O       1.00      1.00      1.00
    33091

  avg / total       1.00      1.00      1.00
    34932

### evaluation of data/twitter_dev.ner; writi
ng to ./twitter_dev.ner.pred
Token-wise accuracy 96.108173702
Token-wise F1 (macro) 32.1729623178
Token-wise F1 (micro) 96.108173702
Sentence-wise accuracy 70.0
               precision    recall  f1-score
  support

    B-company       0.81      0.36      0.50
       36
   B-facility       0.59      0.46      0.52
       28
    B-geo-loc       0.83      0.44      0.58
       77
      B-movie       0.00      0.00      0.00
        7
B-musicartist       0.50      0.08      0.13
       13
      B-other       0.62      0.16      0.25
       63
     B-person       0.66      0.48      0.56
      108
    B-product       0.50      0.16      0.24
       19
 B-sportsteam       0.33      0.09      0.14
       11
     B-tvshow       0.40      0.18      0.25
       11
    I-company       0.00      0.00      0.00
        7
   I-facility       0.72      0.45      0.55
       29
    I-geo-loc       1.00      0.14      0.25
       14
      I-movie       0.00      0.00      0.00
       11
I-musicartist       1.00      0.13      0.24
       15
      I-other       0.68      0.19      0.29
       81
     I-person       0.69      0.54      0.61
       61
    I-product       0.80      0.25      0.38
       16
 I-sportsteam       0.00      0.00      0.00
        4
     I-tvshow       0.50      0.20      0.29
       10
            O       0.97      1.00      0.98
    10916

  avg / total       0.95      0.96      0.95
    11537

### evaluation of data/twitter_dev_test.ner;
writing to ./twitter_dev_test.ner.pred
Token-wise accuracy 91.8995401486
Token-wise F1 (macro) 20.5597986801
Token-wise F1 (micro) 91.8995401486
Sentence-wise accuracy 51.920341394
               precision    recall  f1-score
  support

    B-company       0.68      0.14      0.23
      109
   B-facility       0.55      0.35      0.43
       46
    B-geo-loc       0.76      0.52      0.61
      159
      B-movie       0.00      0.00      0.00
        4
B-musicartist       0.00      0.00      0.00
       33
      B-other       0.10      0.01      0.02
      118
     B-person       0.41      0.43      0.42
       96
    B-product       0.30      0.07      0.11
       44
 B-sportsteam       0.00      0.00      0.00
       31
     B-tvshow       0.00      0.00      0.00
        4
    I-company       0.50      0.08      0.13
       26
   I-facility       0.61      0.23      0.34
       60
    I-geo-loc       0.74      0.38      0.50
       37
      I-movie       0.00      0.00      0.00        10
I-musicartist       0.00      0.00      0.00        15
      I-other       0.50      0.05      0.09       123
     I-person       0.42      0.47      0.44        58
    I-product       0.40      0.02      0.04        88
 I-sportsteam       0.00      0.00      0.00         7
     I-tvshow       0.00      0.00      0.00         9
            O       0.93      0.99      0.96     10231

  avg / total       0.89      0.92      0.90     11308


C:\Users\Harshith Guru Prasad\Desktop\NLP_HW6>perl data/conlleval.pl -d \t < twitter_dev.ner.pred
processed 11537 tokens with 373 phrases; found: 191 phrases; correct: 124.
accuracy:  96.11%; precision:  64.92%; recall:  33.24%; FB1:  43.97
          company: precision:  81.25%; recall:  36.11%; FB1:  50.00  16
         facility: precision:  54.55%; recall:  42.86%; FB1:  48.00  22
          geo-loc: precision:  82.93%; recall:  44.16%; FB1:  57.63  41
            movie: precision:   0.00%; recall:   0.00%; FB1:   0.00  1
      musicartist: precision:  50.00%; recall:   7.69%; FB1:  13.33  2
            other: precision:  56.25%; recall:  14.29%; FB1:  22.78  16
           person: precision:  62.03%; recall:  45.37%; FB1:  52.41  79
          product: precision:  50.00%; recall:  15.79%; FB1:  24.00  6
       sportsteam: precision:  33.33%; recall:   9.09%; FB1:  14.29  3
           tvshow: precision:  40.00%; recall:  18.18%; FB1:  25.00  5
C:\Users\Harshith Guru Prasad\Desktop\NLP_HW6>perl data/conlleval.pl -d \t < twitter_dev_testC:\Users\Harshith Guru Prasad\Desktop\NLP_HW6>perl data/conlleval.pl -d \t < twitter_dev_test.ner
.pred
processed 11308 tokens with 644 phrases; found: 287 phrases; correct: 147.
accuracy:  91.90%; precision:  51.22%; recall:  22.83%; FB1:  31.58
          company: precision:  68.18%; recall:  13.76%; FB1:  22.90  22
         facility: precision:  41.38%; recall:  26.09%; FB1:  32.00  29
          geo-loc: precision:  74.07%; recall:  50.31%; FB1:  59.93  108
            movie: precision:   0.00%; recall:   0.00%; FB1:   0.00  1
      musicartist: precision:   0.00%; recall:   0.00%; FB1:   0.00  2
            other: precision:  10.00%; recall:   0.85%; FB1:   1.56  10
           person: precision:  37.62%; recall:  39.58%; FB1:  38.58  101
          product: precision:  10.00%; recall:   2.27%; FB1:   3.70  10
       sportsteam: precision:   0.00%; recall:   0.00%; FB1:   0.00  3
           tvshow: precision:   0.00%; recall:   0.00%; FB1:   0.00  1
